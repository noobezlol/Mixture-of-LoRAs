{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Auto-generated setup for portability\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    # Assume data is mounted or downloaded to current dir in Colab\n",
    "    BASE_DIR = os.getcwd()\n",
    "else:\n",
    "    # Local execution\n",
    "    BASE_DIR = os.getcwd()\n"
   ],
   "id": "1aff32e1422073e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from groq import Groq, RateLimitError, APIError\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# ======================\n",
    "# CONFIGURATION\n",
    "# ======================\n",
    "# üîë Replace with your real key (or use os.getenv(\"GROQ_API_KEY\"))\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\", \"xxxxxxxxxxxxxxxxxxxx\")\n",
    "if GROQ_API_KEY == \"your_actual_api_key_here\" or not GROQ_API_KEY:\n",
    "    print(\"‚ùå Please set your GROQ_API_KEY environment variable or replace this value with your real API key!\")\n",
    "    print(\"üí° You can set it with: export GROQ_API_KEY='your_actual_key_here'\")\n",
    "    # Instead of raising an error, let's allow the user to set it interactively\n",
    "    import getpass\n",
    "    GROQ_API_KEY = getpass.getpass(\"üîë Enter your Groq API key (or press Enter to skip): \").strip()\n",
    "    if not GROQ_API_KEY:\n",
    "        print(\"‚ö†Ô∏è  No API key provided. The script will run but API calls will fail.\")\n",
    "        GROQ_API_KEY = \"demo_key_that_will_fail\"\n",
    "\n",
    "MODEL_NAME = \"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
    "OUTPUT_FILE = \"code_finetune_dataset.jsonl\"\n",
    "TARGET_TOTAL_EXAMPLES = 1000  # üéØ The desired total number of examples\n",
    "FLUSH_EVERY = 10  # Save to disk every N examples\n",
    "LOG_FILE = \"generation_log.log\"\n",
    "\n",
    "# Rate Limiting Configuration\n",
    "BASE_DELAY = 1.5  # Base delay in seconds between requests (increased from 1.2)\n",
    "MAX_DELAY = 60      # Maximum delay in seconds\n",
    "BACKOFF_FACTOR = 1.5 # Factor by which delay increases after each failure\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(LOG_FILE),\n",
    "        logging.StreamHandler()  # Also print to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "# üß† EXPLICIT PROMPT: tells the model *exactly* what to do\n",
    "GENERATOR_SYSTEM_PROMPT = \"\"\"You are an elite programming assistant. Generate a perfect training example in the following strict format:\n",
    "<thinking>\n",
    "- Restate the problem clearly.\n",
    "- Compare at least two concrete implementation approaches (e.g., \"use a hash map\" vs \"sort first\").\n",
    "- Analyze time and space complexity (Big O) for each.\n",
    "- Choose the best approach and justify why.\n",
    "- List 2‚Äì3 key edge cases (e.g., empty input, duplicates, None).\n",
    "- Do NOT write code here.\n",
    "</thinking>\n",
    "<answer>\n",
    "```python\n",
    "def your_function(...) -> ...:\n",
    "    \\\"\\\"\\\"\n",
    "    Clear docstring: what it does, args, return.\n",
    "    \\\"\\\"\\\"\n",
    "    # Clean, efficient, well-commented code\n",
    "    ...\n",
    "</answer>\n",
    "Rules:\n",
    "    ALWAYS use this exact XML-like format.\n",
    "    NEVER omit <thinking> or <answer>.\n",
    "    Code must be valid, runnable Python with type hints.\n",
    "    NO markdown outside the ```python block.\n",
    "    End with </answer>.\n",
    "    \"\"\"\n",
    "\n",
    "CODE_TOPICS = [\n",
    "    # Data Structures\n",
    "    \"Implement a stack using only queues.\",\n",
    "    \"Create a doubly linked list with insert, delete, and reverse methods.\",\n",
    "    \"Write a function to flatten a nested dictionary.\",\n",
    "    \"Implement an LRU cache with get and put operations.\",\n",
    "    \"Design a circular buffer (ring buffer) in Python.\",\n",
    "    \"Write a function to deep copy a nested list of dictionaries.\",\n",
    "    \"Implement a trie (prefix tree) for word storage and search.\",\n",
    "    \"Create a class for a priority queue using heapq.\",\n",
    "    # Strings & Text\n",
    "    \"Write a function to remove all duplicate characters from a string while preserving order.\",\n",
    "    \"Implement a function to convert a sentence to title case without using built-in methods.\",\n",
    "    \"Create a function that finds the longest common prefix among a list of strings.\",\n",
    "    \"Write a function to replace all spaces in a string with '%20'.\",\n",
    "    \"Implement a function to check if a string is a valid IPv4 address.\",\n",
    "    \"Create a function that splits a camelCase string into words.\",\n",
    "    \"Write a function to compress a string using run-length encoding.\",\n",
    "    \"Implement a function to reverse words in a sentence without reversing letters.\",\n",
    "    # Files & I/O\n",
    "    \"Write a function to read a CSV file and return it as a list of dictionaries.\",\n",
    "    \"Create a function that merges multiple JSON files into one.\",\n",
    "    \"Implement a function to find all files with a given extension in a directory tree.\",\n",
    "    \"Write a function to safely rename all files in a folder with a timestamp prefix.\",\n",
    "    \"Create a context manager that times how long a block of code takes to run.\",\n",
    "    \"Implement a function to backup a file by appending '.bak' and a timestamp.\",\n",
    "    # Web & APIs\n",
    "    \"Write a function to fetch JSON data from a REST API with error handling.\",\n",
    "    \"Create a function that validates a URL using regex and urllib.\",\n",
    "    \"Implement a simple rate-limited API client using time.sleep.\",\n",
    "    \"Write a function to extract all email addresses from a webpage HTML string.\",\n",
    "    \"Create a function that posts form data to a webhook with retries.\",\n",
    "    # Testing & Debugging\n",
    "    \"Write a decorator that logs function calls and execution time.\",\n",
    "    \"Implement a function to generate a random password with configurable rules.\",\n",
    "    \"Create a function that validates a Python dict against a schema.\",\n",
    "    \"Write a function to compare two JSON objects for equality, ignoring key order.\",\n",
    "    # Concurrency\n",
    "    \"Write a function that downloads multiple URLs concurrently using threading.\",\n",
    "    \"Create a thread-safe counter class using locks.\",\n",
    "    \"Implement a producer-consumer queue using Python's queue module.\",\n",
    "    # Utilities\n",
    "    \"Write a function to convert seconds into a human-readable duration string.\",\n",
    "    \"Create a function that parses a command-line argument string into a dict.\",\n",
    "    \"Implement a function to find the most frequent word in a text file.\",\n",
    "    \"Write a function to generate a UUID v4 without using the uuid module.\",\n",
    "    \"Create a function that validates a credit card number using the Luhn algorithm.\",\n",
    "    \"Implement a function to parse a log file and count error occurrences.\",\n",
    "    # OOP & Design\n",
    "    \"Create a singleton class in Python.\",\n",
    "    \"Implement the observer pattern for a simple event system.\",\n",
    "    \"Write a class that represents a bank account with deposit/withdraw methods.\",\n",
    "    \"Create a plugin system using abstract base classes.\",\n",
    "    # More Practical Tasks\n",
    "    \"Write a function to sanitize user input for SQL queries (basic escaping).\",\n",
    "    \"Implement a function to convert a Python dict to a URL query string.\",\n",
    "    \"Create a function that detects if two rectangles overlap (given as (x1,y1,x2,y2)).\",\n",
    "    \"Write a function to parse a date string in multiple formats and return a datetime.\",\n",
    "    \"Implement a function to calculate the difference between two dates in human terms.\",\n",
    "    \"Create a function that validates a phone number in E.164 format.\",\n",
    "    \"Write a function to extract the domain from an email address.\",\n",
    "    \"Implement a function to generate a slug from a title string.\",\n",
    "    \"Create a function that checks if a file is binary or text.\",\n",
    "    \"Write a function to rotate a 2D matrix 90 degrees clockwise in-place.\",\n",
    "    \"Implement a function to find the intersection of two lists without duplicates.\",\n",
    "    \"Create a function that batches a list into chunks of size N.\",\n",
    "    \"Write a function to validate a JSON Web Token (JWT) signature (mock implementation).\",\n",
    "    \"Implement a function to convert a list of dicts to a pandas-like table string.\",\n",
    "    \"Create a function that finds the first non-repeating character in a string.\",\n",
    "    \"Write a function to implement a simple state machine for parsing commands.\",\n",
    "    \"Implement a function to calculate the checksum of a file.\",\n",
    "    \"Create a function that converts a snake_case string to camelCase.\",\n",
    "    \"Write a function to parse a simple INI config file into a dictionary.\",\n",
    "    \"Implement a function to find all anagrams of a word in a given word list.\",\n",
    "    \"Create a function that validates a username against common rules.\",\n",
    "    \"Write a function to implement a basic spell checker using edit distance.\",\n",
    "    \"Implement a function to generate a Fibonacci sequence as a generator.\",\n",
    "    \"Create a function that merges overlapping intervals.\",\n",
    "    \"Write a function to detect if a linked list has a cycle using Floyd's algorithm.\",\n",
    "    \"Implement a function to serialize and deserialize a binary tree.\",\n",
    "    \"Create a function that finds the kth largest element in an unsorted list.\",\n",
    "    \"Write a function to implement a simple key-value store with TTL (time-to-live).\",\n",
    "    \"Implement a function to parse a simple arithmetic expression (e.g., '2+3*4').\",\n",
    "    \"Create a function that validates a Sudoku board.\",\n",
    "    \"Write a function to implement a basic breadth-first search on a grid.\",\n",
    "    \"Implement a function to find the shortest path in a maze using BFS.\",\n",
    "    \"Create a function that converts a decimal number to binary without bin().\",\n",
    "    \"Write a function to implement a simple in-memory message queue.\",\n",
    "    \"Implement a function to calculate the median of a stream of numbers.\",\n",
    "    \"Create a function that validates a YAML-like indentation structure.\",\n",
    "    \"Write a function to implement a basic autocomplete using a trie.\",\n",
    "    \"Implement a function to find all subsets of a set (power set).\",\n",
    "    \"Create a function that validates a CSS color hex code.\",\n",
    "    \"Write a function to implement a simple template engine with {{variable}} substitution.\",\n",
    "    \"Implement a function to parse a command like 'ls -l /home' into args and options.\",\n",
    "    \"Create a function that detects memory leaks by tracking object counts (mock).\",\n",
    "    \"Write a function to implement a basic rate limiter using a token bucket.\",\n",
    "    \"Implement a function to convert a Python dict to a JSON-serializable dict.\",\n",
    "    \"Create a function that finds the longest palindromic substring.\",\n",
    "    \"Write a function to implement a simple event emitter/listener pattern.\",\n",
    "    \"Implement a function to validate a JWT payload expiration (mock).\",\n",
    "    \"Create a function that converts a list of objects to CSV format.\",\n",
    "    \"Write a function to implement a basic cache decorator with TTL.\",\n",
    "    \"Implement a function to find the minimum window substring.\",\n",
    "    \"Create a function that validates a cron expression (simplified).\",\n",
    "    \"Write a function to implement a simple dependency resolver.\",\n",
    "    \"Implement a function to calculate the edit distance between two strings.\",\n",
    "    \"Create a function that parses a simple query string like 'name=John&age=30'.\",\n",
    "    \"Write a function to implement a basic circuit breaker pattern.\",\n",
    "    \"Implement a function to find the top K frequent elements in a list.\",\n",
    "    \"Create a function that validates a file path for security (no '../').\",\n",
    "    \"Write a function to implement a simple bloom filter.\",\n",
    "    \"Implement a function to convert a nested dict to a flat dict with dot notation keys.\",\n",
    "    \"Create a function that finds the longest increasing subsequence.\",\n",
    "    \"Write a function to implement a simple object pool pattern.\",\n",
    "    \"Implement a function to validate a GraphQL query structure (mock).\",\n",
    "    \"Create a function that converts a list of tuples to a dictionary.\",\n",
    "    \"Write a function to implement a simple state machine for order processing.\",\n",
    "    \"Implement a function to find the maximum product subarray.\",\n",
    "    \"Create a function that validates a Dockerfile instruction (mock).\",\n",
    "    \"Write a function to implement a basic retry mechanism with exponential backoff.\",\n",
    "    \"Implement a function to convert a Python enum to a list of choices.\",\n",
    "    \"Create a function that finds the shortest unique prefix for each word.\",\n",
    "    \"Write a function to implement a simple feature flag system.\",\n",
    "    \"Implement a function to validate a Kubernetes YAML manifest (mock).\",\n",
    "    \"Create a function that converts a list of objects to a markdown table.\",\n",
    "    \"Write a function to implement a basic circuit breaker with failure threshold.\",\n",
    "    \"Implement a function to find the maximum sum path in a triangle.\",\n",
    "    \"Create a function that validates a Prometheus metric name.\",\n",
    "    \"Write a function to implement a simple rate limiter using sliding window.\",\n",
    "    \"Implement a function to convert a nested JSON to a flat JSON with path keys.\",\n",
    "    \"Create a function that finds the longest common subsequence.\",\n",
    "    \"Write a function to implement a basic object validator with rules.\",\n",
    "    \"Implement a function to validate a Terraform HCL block (mock).\",\n",
    "    \"Create a function that converts a list of objects to an Excel file (mock with openpyxl).\",\n",
    "    \"Write a function to implement a simple service registry pattern.\",\n",
    "    \"Implement a function to find the minimum number of coins for a given amount.\",\n",
    "    \"Create a function that validates a CloudFormation template (mock).\",\n",
    "    \"Write a function to implement a basic circuit breaker with half-open state.\",\n",
    "    \"Implement a function to convert a Python dataclass to a JSON schema.\",\n",
    "    \"Create a function that finds the maximum area of a histogram rectangle.\",\n",
    "    \"Write a function to implement a simple feature toggle with environment variables.\",\n",
    "    \"Implement a function to validate an OpenAPI spec operation (mock).\",\n",
    "    \"Create a function that converts a list of objects to a CSV string.\",\n",
    "    \"Write a function to implement a basic cache decorator with TTL.\",\n",
    "    \"Implement a function to find the minimum window substring.\",\n",
    "    \"Create a function that validates a cron expression (simplified).\",\n",
    "    \"Write a function to implement a simple dependency resolver.\",\n",
    "    \"Implement a function to calculate the edit distance between two strings.\",\n",
    "    \"Create a function that parses a simple query string like 'name=John&age=30'.\",\n",
    "    \"Write a function to implement a basic circuit breaker pattern.\",\n",
    "    \"Implement a function to find the top K frequent elements in a list.\",\n",
    "    \"Create a function that validates a file path for security (no '../').\",\n",
    "    \"Write a function to implement a simple bloom filter.\",\n",
    "    \"Implement a function to convert a nested dict to a flat dict with dot notation keys.\",\n",
    "    \"Create a function that finds the longest increasing subsequence.\",\n",
    "    \"Write a function to implement a simple object pool pattern.\",\n",
    "    \"Implement a function to validate a GraphQL query structure (mock).\",\n",
    "    \"Create a function that converts a list of tuples to a dictionary.\",\n",
    "    \"Write a function to implement a simple state machine for order processing.\",\n",
    "    \"Implement a function to find the maximum product subarray.\",\n",
    "    \"Create a function that validates a Dockerfile instruction (mock).\",\n",
    "    \"Write a function to implement a basic retry mechanism with exponential backoff.\",\n",
    "    \"Implement a function to convert a Python enum to a list of choices.\",\n",
    "    \"Create a function that finds the shortest unique prefix for each word.\",\n",
    "    \"Write a function to implement a simple feature flag system.\",\n",
    "    \"Implement a function to validate a Kubernetes YAML manifest (mock).\",\n",
    "    \"Create a function that converts a list of objects to a markdown table.\",\n",
    "    \"Write a function to implement a basic circuit breaker with failure threshold.\",\n",
    "    \"Implement a function to find the maximum sum path in a triangle.\",\n",
    "    \"Create a function that validates a Prometheus metric name.\",\n",
    "    \"Write a function to implement a simple rate limiter using sliding window.\",\n",
    "    \"Implement a function to convert a nested JSON to a flat JSON with path keys.\",\n",
    "    \"Create a function that finds the longest common subsequence.\",\n",
    "    \"Write a function to implement a basic object validator with rules.\",\n",
    "    \"Implement a function to validate a Terraform HCL block (mock).\",\n",
    "    \"Create a function that converts a list of objects to an Excel file (mock with openpyxl).\",\n",
    "    \"Write a function to implement a simple service registry pattern.\",\n",
    "    \"Implement a function to find the minimum number of coins for a given amount.\",\n",
    "    \"Create a function that validates a CloudFormation template (mock).\",\n",
    "    \"Write a function to implement a basic circuit breaker with half-open state.\",\n",
    "    \"Implement a function to convert a Python dataclass to a JSON schema.\",\n",
    "    \"Create a function that finds the maximum area of a histogram rectangle.\",\n",
    "    \"Write a function to implement a simple feature toggle with environment variables.\",\n",
    "    \"Implement a function to validate an OpenAPI spec operation (mock).\",\n",
    "    \"Create a function that converts a list of objects to a CSV string.\",\n",
    "    \"Write a function to implement a basic retry mechanism with circuit breaker.\",\n",
    "    \"Implement a function to find the longest palindromic subsequence.\",\n",
    "    \"Create a function that validates a Helm chart values file (mock).\",\n",
    "    \"Write a function to implement a simple object pool for database connections.\",\n",
    "    \"Implement a function to convert a nested dict to a protobuf-like message (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a contiguous subarray.\",\n",
    "    \"Write a function to implement a basic rate limiter using Redis (mock).\",\n",
    "    \"Implement a function to validate a GitHub Actions workflow (mock).\",\n",
    "    \"Create a function that converts a list of objects to a JSON Lines string.\",\n",
    "    \"Write a function to implement a simple circuit breaker with metrics.\",\n",
    "    \"Implement a function to find the minimum path sum in a grid.\",\n",
    "    \"Create a function that validates a Docker Compose service (mock).\",\n",
    "    \"Write a function to implement a basic retry mechanism with circuit breaker.\",\n",
    "    \"Implement a function to convert a Python class to a TypeScript interface (mock).\",\n",
    "    \"Create a function that finds the maximum profit from stock prices.\",\n",
    "    \"Write a function to implement a simple feature flag with user targeting.\",\n",
    "    \"Implement a function to validate a Kubernetes deployment spec (mock).\",\n",
    "    \"Create a function that converts a list of objects to a Parquet file (mock).\",\n",
    "    \"Write a function to implement a basic object validator with custom rules.\",\n",
    "    \"Implement a function to find the longest substring with at most K distinct characters.\",\n",
    "    \"Create a function that validates a Terraform variable block (mock).\",\n",
    "    \"Write a function to implement a simple service discovery pattern.\",\n",
    "    \"Implement a function to convert a nested JSON to a GraphQL query (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a non-adjacent subarray.\",\n",
    "    \"Write a function to implement a basic rate limiter with distributed lock (mock).\",\n",
    "    \"Implement a function to validate a CloudFormation resource (mock).\",\n",
    "    \"Create a function that converts a list of objects to an Avro schema (mock).\",\n",
    "    \"Write a function to implement a simple circuit breaker with logging.\",\n",
    "    \"Implement a function to find the minimum number of jumps to reach end.\",\n",
    "    \"Create a function that validates a Prometheus alert rule (mock).\",\n",
    "    \"Write a function to implement a basic retry mechanism with circuit breaker and logging.\",\n",
    "    \"Implement a function to convert a Python function to a CLI command (mock with argparse).\",\n",
    "    \"Create a function that finds the maximum sum of a submatrix.\",\n",
    "    \"Write a function to implement a simple feature flag with A/B testing.\",\n",
    "    \"Implement a function to validate a GitHub repository settings (mock).\",\n",
    "    \"Create a function that converts a list of objects to a BigQuery schema (mock).\",\n",
    "    \"Write a function to implement a basic object pool with health checks.\",\n",
    "    \"Implement a function to find the longest common substring.\",\n",
    "    \"Create a function that validates a Docker image tag (mock).\",\n",
    "    \"Write a function to implement a simple rate limiter with token bucket and sliding window.\",\n",
    "    \"Implement a function to find the maximum sum of a path in a binary tree.\",\n",
    "    \"Write a function to implement a basic circuit breaker with fallback function.\",\n",
    "    \"Implement a function to validate a Kubernetes ingress spec (mock).\",\n",
    "    \"Create a function that converts a list of objects to a Firestore collection (mock).\",\n",
    "    \"Write a function to implement a simple retry mechanism with exponential backoff and jitter.\",\n",
    "    \"Implement a function to find the minimum window that contains all characters of a string.\",\n",
    "    \"Create a function that validates a Helm chart template (mock).\",\n",
    "    \"Write a function to implement a basic object validator with nested rules.\",\n",
    "    \"Implement a function to convert a Python class to a JSON schema with OpenAPI extensions.\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with length at least K.\",\n",
    "    \"Write a function to implement a simple feature flag with percentage rollout.\",\n",
    "    \"Implement a function to validate a Terraform provider block (mock).\",\n",
    "    \"Create a function that converts a list of objects to a Snowflake table DDL (mock).\",\n",
    "    \"Write a function to implement a basic rate limiter with Redis and Lua script (mock).\",\n",
    "    \"Implement a function to find the longest increasing subsequence with binary search.\",\n",
    "    \"Create a function that validates a Docker network config (mock).\",\n",
    "    \"Write a function to implement a simple circuit breaker with metrics and logging.\",\n",
    "    \"Implement a function to convert a nested JSON to a Protobuf message (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with no two elements adjacent.\",\n",
    "    \"Write a function to implement a basic retry mechanism with circuit breaker, logging, and metrics.\",\n",
    "    \"Implement a function to validate a CloudFormation parameter (mock).\",\n",
    "    \"Create a function that converts a list of objects to a Delta Lake table (mock).\",\n",
    "    \"Write a function to implement a simple feature flag with user attributes.\",\n",
    "    \"Implement a function to find the minimum number of operations to make array equal.\",\n",
    "    \"Create a function that validates a Prometheus recording rule (mock).\",\n",
    "    \"Write a function to implement a basic object pool with connection reuse.\",\n",
    "    \"Implement a function to convert a Python dataclass to a GraphQL type (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with exactly K elements.\",\n",
    "    \"Write a function to implement a simple rate limiter with distributed token bucket.\",\n",
    "    \"Implement a function to validate a GitHub Actions job (mock).\",\n",
    "    \"Create a function that converts a list of objects to a Cassandra table schema (mock).\",\n",
    "    \"Write a function to implement a basic circuit breaker with half-open state and metrics.\",\n",
    "    \"Implement a function to find the longest palindromic substring with Manacher's algorithm (simplified).\",\n",
    "    \"Create a function that validates a Docker volume config (mock).\",\n",
    "    \"Write a function to implement a simple retry mechanism with circuit breaker and exponential backoff.\",\n",
    "    \"Implement a function to convert a nested dict to a YAML string with comments (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with at most K elements.\",\n",
    "    \"Write a function to implement a simple feature flag with environment and user targeting.\",\n",
    "    \"Implement a function to validate a Kubernetes ingress spec (mock).\",\n",
    "    \"Create a function that converts a list of objects to a Bigtable schema (mock).\",\n",
    "    \"Write a function to implement a simple object validator with custom error messages.\",\n",
    "    \"Implement a function to find the minimum number of coins to make change with dynamic programming.\",\n",
    "    \"Create a function that validates a Terraform output block (mock).\",\n",
    "    \"Write a function to implement a basic rate limiter with sliding window and Redis.\",\n",
    "    \"Implement a function to convert a Python function to a FastAPI endpoint (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with no duplicates.\",\n",
    "    \"Write a function to implement a basic circuit breaker with fallback and logging.\",\n",
    "    \"Implement a function to validate a CloudFormation mapping (mock).\",\n",
    "    \"Create a function that converts a list of objects to a DynamoDB table schema (mock).\",\n",
    "    \"Write a function to implement a simple retry mechanism with jitter and circuit breaker.\",\n",
    "    \"Implement a function to find the longest common subsequence with space optimization.\",\n",
    "    \"Create a function that validates a Docker secret config (mock).\",\n",
    "    \"Write a function to implement a simple feature flag with A/B testing and metrics.\",\n",
    "    \"Implement a function to convert a nested JSON to a Avro schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with at least K elements.\",\n",
    "    \"Write a function to implement a basic rate limiter with token bucket and Redis.\",\n",
    "    \"Implement a function to validate a GitHub Actions workflow job (mock).\",\n",
    "    \"Create a function that converts a list of objects to a Redshift table DDL (mock).\",\n",
    "    \"Write a function to implement a simple circuit breaker with metrics, logging, and half-open state.\",\n",
    "    \"Implement a function to find the minimum number of operations to sort an array.\",\n",
    "    \"Create a function that validates a Kubernetes configmap spec (mock).\",\n",
    "    \"Write a function to implement a basic object validator with nested rules and custom errors.\",\n",
    "    \"Implement a function to convert a Python class to a OpenAPI schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with exactly K distinct elements.\",\n",
    "    \"Write a function to implement a simple rate limiter with token bucket, sliding window, and Redis.\",\n",
    "    \"Implement a function to validate a GitHub Actions workflow trigger (mock).\",\n",
    "    \"Create a function that converts a list of objects to a PostgreSQL table DDL (mock).\",\n",
    "    \"Write a function to implement a basic circuit breaker with all features: fallback, logging, metrics, half-open state, and error threshold.\",\n",
    "    \"Implement a function to find the longest common subsequence with reconstruction.\",\n",
    "    \"Create a function that validates a Docker healthcheck config (mock).\",\n",
    "    \"Write a function to implement a simple retry mechanism with all features: exponential backoff, jitter, circuit breaker, and logging.\",\n",
    "    \"Implement a function to convert a nested JSON to a GraphQL schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with constraints on element values.\",\n",
    "    \"Write a function to implement a basic feature flag with all features: A/B testing, percentage rollout, user targeting, and environment rules.\",\n",
    "    \"Implement a function to validate a Terraform resource block (mock).\",\n",
    "    \"Create a function that converts a list of objects to a MySQL table DDL (mock).\",\n",
    "    \"Write a function to implement a simple rate limiter with all features: token bucket, sliding window, Redis, and distributed lock.\",\n",
    "    \"Implement a function to find the minimum number of operations to transform one string to another.\",\n",
    "    \"Create a function that validates a Kubernetes pod spec (mock).\",\n",
    "    \"Write a function to implement a basic object validator with all features: nested rules, custom errors, type checking, and schema validation.\",\n",
    "    \"Implement a function to convert a Python class to a JSON Schema with all OpenAPI extensions (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with dynamic constraints.\",\n",
    "    \"Write a function to implement a simple circuit breaker with maximum configurability.\",\n",
    "    \"Implement a function to validate a CloudFormation resource property (mock).\",\n",
    "    \"Create a function that converts a list of objects to a SQLite table DDL (mock).\",\n",
    "    \"Write a function to implement a simple retry mechanism with all possible features and configurations.\",\n",
    "    \"Implement a function to find the longest common subsequence with dynamic programming and space optimization.\",\n",
    "    \"Create a function that validates a Docker compose service network config (mock).\",\n",
    "    \"Write a function to implement a simple feature flag with all possible features and configurations.\",\n",
    "    \"Implement a function to convert a nested dict to a ultimate Protocol Buffers schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with advanced constraints.\",\n",
    "    \"Write a function to implement a basic rate limiter with all possible features and configurations.\",\n",
    "    \"Implement a function to validate a GitHub Actions workflow environment (mock).\",\n",
    "    \"Create a function that converts a list of objects to a Oracle table DDL (mock).\",\n",
    "    \"Write a function to implement a simple circuit breaker with maximum configurability.\",\n",
    "    \"Implement a function to find the minimum number of operations to solve a dynamic programming problem.\",\n",
    "    \"Create a function that validates a Kubernetes deployment strategy (mock).\",\n",
    "    \"Write a function to implement a basic object validator with maximum configurability.\",\n",
    "    \"Implement a function to convert a Python dataclass to a full OpenAPI specification (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with maximum complexity.\",\n",
    "    \"Write a function to implement a simple feature flag with maximum configurability.\",\n",
    "    \"Implement a function to validate a Terraform backend block (mock).\",\n",
    "    \"Create a function that converts a list of objects to a SQL Server table DDL (mock).\",\n",
    "    \"Write a function to implement a basic rate limiter with maximum configurability.\",\n",
    "    \"Implement a function to find the longest common subsequence with maximum complexity.\",\n",
    "    \"Create a function that validates a Docker compose service deploy config (mock).\",\n",
    "    \"Write a function to implement a simple retry mechanism with maximum configurability.\",\n",
    "    \"Implement a function to convert a nested JSON to a full GraphQL schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with maximum constraints.\",\n",
    "    \"Write a function to implement a basic circuit breaker with maximum configurability and all features.\",\n",
    "    \"Implement a function to validate a CloudFormation template metadata (mock).\",\n",
    "    \"Create a function that converts a list of objects to a DB2 table DDL (mock).\",\n",
    "    \"Write a function to implement a simple feature flag with maximum configurability and all features.\",\n",
    "    \"Implement a function to find the minimum number of operations to solve a complex dynamic programming problem.\",\n",
    "    \"Create a function that validates a Kubernetes service account spec (mock).\",\n",
    "    \"Write a function to implement a basic object validator with maximum configurability and all features.\",\n",
    "    \"Implement a function to convert a Python class to a full GraphQL schema with all types (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with maximum advanced constraints.\",\n",
    "    \"Write a function to implement a simple rate limiter with maximum configurability and all features.\",\n",
    "    \"Implement a function to validate a GitHub Actions workflow permission (mock).\",\n",
    "    \"Create a function that converts a list of objects to a Sybase table DDL (mock).\",\n",
    "    \"Write a function to implement a basic circuit breaker with ultimate configurability.\",\n",
    "    \"Implement a function to find the longest common subsequence with ultimate complexity.\",\n",
    "    \"Create a function that validates a Docker compose volume driver config (mock).\",\n",
    "    \"Write a function to implement a simple retry mechanism with ultimate configurability.\",\n",
    "    \"Implement a function to convert a nested dict to a ultimate Protocol Buffers schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with ultimate constraints.\",\n",
    "    \"Write a function to implement a basic feature flag with ultimate configurability.\",\n",
    "    \"Implement a function to validate a Terraform provider alias (mock).\",\n",
    "    \"Create a function that converts a list of objects to a ultimate SQL table DDL (mock).\",\n",
    "    \"Write a function to implement a simple rate limiter with ultimate configurability.\",\n",
    "    \"Implement a function to find the minimum number of operations to solve a ultimate dynamic programming problem.\",\n",
    "    \"Create a function that validates a Kubernetes role binding spec (mock).\",\n",
    "    \"Write a function to implement a basic object validator with ultimate configurability.\",\n",
    "    \"Implement a function to convert a Python dataclass to a ultimate OpenAPI specification (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with ultimate advanced constraints.\",\n",
    "    \"Write a function to implement a simple circuit breaker with god mode configurability.\",\n",
    "    \"Implement a function to validate a CloudFormation template transform (mock).\",\n",
    "    \"Create a function that converts a list of objects to a god mode SQL table DDL (mock).\",\n",
    "    \"Write a function to implement a simple feature flag with god mode configurability.\",\n",
    "    \"Implement a function to find the longest common subsequence with god mode complexity.\",\n",
    "    \"Create a function that validates a Docker compose service deploy config (mock).\",\n",
    "    \"Write a function to implement a simple rate limiter with god mode configurability.\",\n",
    "    \"Implement a function to convert a nested dict to a god mode Protocol Buffers schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with god mode constraints.\",\n",
    "    \"Write a function to implement a simple retry mechanism with god mode configurability.\",\n",
    "    \"Implement a function to validate a GitHub Actions workflow concurrency (mock).\",\n",
    "    \"Create a function that converts a list of objects to a god mode database schema (mock).\",\n",
    "    \"Write a function to implement a simple circuit breaker with infinite configurability.\",\n",
    "    \"Implement a function to find the minimum number of operations to solve a infinite dynamic programming problem.\",\n",
    "    \"Create a function that validates a Kubernetes cluster role spec (mock).\",\n",
    "    \"Write a function to implement a basic object validator with infinite configurability.\",\n",
    "    \"Implement a function to convert a Python class to a infinite OpenAPI specification (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with infinite constraints.\",\n",
    "    \"Write a function to implement a simple feature flag with infinite configurability.\",\n",
    "    \"Implement a function to validate a Terraform required providers block (mock).\",\n",
    "    \"Create a function that converts a list of objects to a infinite SQL table DDL (mock).\",\n",
    "    \"Write a function to implement a basic rate limiter with infinite configurability.\",\n",
    "    \"Implement a function to find the longest common subsequence with infinite complexity.\",\n",
    "    \"Create a function that validates a Docker compose service healthcheck config (mock).\",\n",
    "    \"Write a function to implement a simple retry mechanism with infinite configurability.\",\n",
    "    \"Implement a function to convert a nested dict to a infinite Protocol Buffers schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with infinite advanced constraints.\",\n",
    "    \"Write a function to implement a basic circuit breaker with absolute maximum configurability.\",\n",
    "    \"Implement a function to validate a CloudFormation template AWSTemplateFormatVersion (mock).\",\n",
    "    \"Create a function that converts a list of objects to a absolute maximum SQL table DDL (mock).\",\n",
    "    \"Write a function to implement a simple feature flag with absolute maximum configurability.\",\n",
    "    \"Implement a function to find the minimum number of operations to solve a absolute maximum dynamic programming problem.\",\n",
    "    \"Create a function that validates a Kubernetes role spec (mock).\",\n",
    "    \"Write a function to implement a basic object validator with absolute maximum configurability.\",\n",
    "    \"Implement a function to convert a Python dataclass to a absolute maximum OpenAPI specification (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with absolute maximum constraints.\",\n",
    "    \"Write a function to implement a simple rate limiter with absolute maximum configurability.\",\n",
    "    \"Implement a function to find the longest common subsequence with absolute maximum complexity.\",\n",
    "    \"Create a function that validates a Docker compose service logging config (mock).\",\n",
    "    \"Write a function to implement a simple retry mechanism with absolute maximum configurability.\",\n",
    "    \"Implement a function to convert a nested dict to a absolute maximum Protocol Buffers schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with absolute maximum advanced constraints.\",\n",
    "    \"Write a function to implement a basic circuit breaker with beyond maximum configurability.\",\n",
    "    \"Implement a function to validate a GitHub Actions workflow defaults (mock).\",\n",
    "    \"Create a function that converts a list of objects to a beyond maximum SQL table DDL (mock).\",\n",
    "    \"Write a function to implement a simple feature flag with beyond maximum configurability.\",\n",
    "    \"Implement a function to find the minimum number of operations to solve a beyond maximum dynamic programming problem.\",\n",
    "    \"Create a function that validates a Kubernetes service spec ports (mock).\",\n",
    "    \"Write a function to implement a basic object validator with beyond maximum configurability.\",\n",
    "    \"Implement a function to convert a Python class to a beyond maximum OpenAPI specification (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with beyond maximum constraints.\",\n",
    "    \"Write a function to implement a simple rate limiter with beyond maximum configurability.\",\n",
    "    \"Implement a function to find the longest common subsequence with beyond maximum complexity.\",\n",
    "    \"Create a function that validates a Docker compose service ulimits config (mock).\",\n",
    "    \"Write a function to implement a simple retry mechanism with beyond maximum configurability.\",\n",
    "    \"Implement a function to convert a nested dict to a beyond maximum Protocol Buffers schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with beyond maximum advanced constraints.\",\n",
    "    \"Write a function to implement a basic circuit breaker with ultimate beyond maximum configurability.\",\n",
    "    \"Implement a function to validate a CloudFormation template description (mock).\",\n",
    "    \"Create a function that converts a list of objects to a ultimate beyond maximum SQL table DDL (mock).\",\n",
    "    \"Write a function to implement a simple feature flag with ultimate beyond maximum configurability.\",\n",
    "    \"Implement a function to find the minimum number of operations to solve a ultimate beyond maximum dynamic programming problem.\",\n",
    "    \"Create a function that validates a Kubernetes deployment spec replicas (mock).\",\n",
    "    \"Write a function to implement a basic object validator with ultimate beyond maximum configurability.\",\n",
    "    \"Implement a function to convert a Python dataclass to a ultimate beyond maximum OpenAPI specification (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with ultimate beyond maximum constraints.\",\n",
    "    \"Write a function to implement a simple rate limiter with ultimate beyond maximum configurability.\",\n",
    "    \"Implement a function to find the longest common subsequence with ultimate beyond maximum complexity.\",\n",
    "    \"Create a function that validates a Docker compose service pid config (mock).\",\n",
    "    \"Write a function to implement a simple retry mechanism with ultimate beyond maximum configurability.\",\n",
    "    \"Implement a function to convert a nested dict to a ultimate beyond maximum Protocol Buffers schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with ultimate beyond maximum advanced constraints.\",\n",
    "    \"Write a function to implement a basic circuit breaker with god mode configurability.\",\n",
    "    \"Implement a function to validate a CloudFormation template description (mock).\",\n",
    "    \"Create a function that converts a list of objects to a god mode SQL table DDL (mock).\",\n",
    "    \"Write a function to implement a simple feature flag with god mode configurability.\",\n",
    "    \"Implement a function to find the longest common subsequence with god mode complexity.\",\n",
    "    \"Create a function that validates a Docker compose service deploy config (mock).\",\n",
    "    \"Write a function to implement a simple rate limiter with god mode configurability.\",\n",
    "    \"Implement a function to convert a nested dict to a god mode Protocol Buffers schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with god mode constraints.\",\n",
    "    \"Write a function to implement a simple retry mechanism with god mode configurability.\",\n",
    "    \"Implement a function to validate a GitHub Actions workflow concurrency (mock).\",\n",
    "    \"Create a function that converts a list of objects to a god mode database schema (mock).\",\n",
    "    \"Write a function to implement a simple circuit breaker with infinite configurability.\",\n",
    "    \"Implement a function to find the minimum number of operations to solve a infinite dynamic programming problem.\",\n",
    "    \"Create a function that validates a Kubernetes cluster role spec (mock).\",\n",
    "    \"Write a function to implement a basic object validator with infinite configurability.\",\n",
    "    \"Implement a function to convert a Python class to a infinite OpenAPI specification (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with infinite constraints.\",\n",
    "    \"Write a function to implement a simple feature flag with infinite configurability.\",\n",
    "    \"Implement a function to validate a Terraform required providers block (mock).\",\n",
    "    \"Create a function that converts a list of objects to a infinite SQL table DDL (mock).\",\n",
    "    \"Write a function to implement a basic rate limiter with infinite configurability.\",\n",
    "    \"Implement a function to find the longest common subsequence with infinite complexity.\",\n",
    "    \"Create a function that validates a Docker compose service healthcheck config (mock).\",\n",
    "    \"Write a function to implement a simple retry mechanism with infinite configurability.\",\n",
    "    \"Implement a function to convert a nested dict to a infinite Protocol Buffers schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with infinite advanced constraints.\",\n",
    "    \"Write a function to implement a basic circuit breaker with absolute maximum configurability.\",\n",
    "    \"Implement a function to validate a CloudFormation template AWSTemplateFormatVersion (mock).\",\n",
    "    \"Create a function that converts a list of objects to a absolute maximum SQL table DDL (mock).\",\n",
    "    \"Write a function to implement a simple feature flag with absolute maximum configurability.\",\n",
    "    \"Implement a function to find the minimum number of operations to solve a absolute maximum dynamic programming problem.\",\n",
    "    \"Create a function that validates a Kubernetes role spec (mock).\",\n",
    "    \"Write a function to implement a basic object validator with absolute maximum configurability.\",\n",
    "    \"Implement a function to convert a Python dataclass to a absolute maximum OpenAPI specification (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with absolute maximum constraints.\",\n",
    "    \"Write a function to implement a simple rate limiter with absolute maximum configurability.\",\n",
    "    \"Implement a function to find the longest common subsequence with absolute maximum complexity.\",\n",
    "    \"Create a function that validates a Docker compose service logging config (mock).\",\n",
    "    \"Write a function to implement a simple retry mechanism with absolute maximum configurability.\",\n",
    "    \"Implement a function to convert a nested dict to a absolute maximum Protocol Buffers schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with absolute maximum advanced constraints.\",\n",
    "    \"Write a function to implement a basic circuit breaker with beyond maximum configurability.\",\n",
    "    \"Implement a function to validate a GitHub Actions workflow defaults (mock).\",\n",
    "    \"Create a function that converts a list of objects to a beyond maximum SQL table DDL (mock).\",\n",
    "    \"Write a function to implement a simple feature flag with beyond maximum configurability.\",\n",
    "    \"Implement a function to find the minimum number of operations to solve a beyond maximum dynamic programming problem.\",\n",
    "    \"Create a function that validates a Kubernetes service spec ports (mock).\",\n",
    "    \"Write a function to implement a basic object validator with beyond maximum configurability.\",\n",
    "    \"Implement a function to convert a Python class to a beyond maximum OpenAPI specification (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with beyond maximum constraints.\",\n",
    "    \"Write a function to implement a simple rate limiter with beyond maximum configurability.\",\n",
    "    \"Implement a function to find the longest common subsequence with beyond maximum complexity.\",\n",
    "    \"Create a function that validates a Docker compose service ulimits config (mock).\",\n",
    "    \"Write a function to implement a simple retry mechanism with beyond maximum configurability.\",\n",
    "    \"Implement a function to convert a nested dict to a beyond maximum Protocol Buffers schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with beyond maximum advanced constraints.\",\n",
    "    \"Write a function to implement a basic circuit breaker with ultimate beyond maximum configurability.\",\n",
    "    \"Implement a function to validate a CloudFormation template description (mock).\",\n",
    "    \"Create a function that converts a list of objects to a ultimate beyond maximum SQL table DDL (mock).\",\n",
    "    \"Write a function to implement a simple feature flag with ultimate beyond maximum configurability.\",\n",
    "    \"Implement a function to find the minimum number of operations to solve a ultimate beyond maximum dynamic programming problem.\",\n",
    "    \"Create a function that validates a Kubernetes deployment spec replicas (mock).\",\n",
    "    \"Write a function to implement a basic object validator with ultimate beyond maximum configurability.\",\n",
    "    \"Implement a function to convert a Python dataclass to a ultimate beyond maximum OpenAPI specification (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with ultimate beyond maximum constraints.\",\n",
    "    \"Write a function to implement a simple rate limiter with ultimate beyond maximum configurability.\",\n",
    "    \"Implement a function to find the longest common subsequence with ultimate beyond maximum complexity.\",\n",
    "    \"Create a function that validates a Docker compose service pid config (mock).\",\n",
    "    \"Write a function to implement a simple retry mechanism with ultimate beyond maximum configurability.\",\n",
    "    \"Implement a function to convert a nested dict to a ultimate beyond maximum Protocol Buffers schema (mock).\",\n",
    "    \"Create a function that finds the maximum sum of a subarray with ultimate beyond maximum advanced constraints.\",\n",
    "]\n",
    "\n",
    "def count_existing_examples(file_path):\n",
    "    \"\"\"Counts the number of valid JSONL entries in the file.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.info(f\"Output file '{file_path}' does not exist. Starting from scratch.\")\n",
    "        return 0\n",
    "\n",
    "    count = 0\n",
    "    invalid_lines = 0\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, start=1):\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                try:\n",
    "                    record = json.loads(line)\n",
    "                    # Basic check for required keys and structure (optional but recommended)\n",
    "                    if isinstance(record, dict) and 'prompt' in record and 'chosen' in record:\n",
    "                        count += 1\n",
    "                    else:\n",
    "                        logging.warning(f\"Line {line_num} in '{file_path}' has unexpected structure: {record}\")\n",
    "                        invalid_lines += 1\n",
    "                except json.JSONDecodeError as e:\n",
    "                    logging.error(f\"JSON decode error on line {line_num} in '{file_path}': {e}\")\n",
    "                    invalid_lines += 1\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading file '{file_path}': {e}\")\n",
    "        return 0 # Return 0 if file cannot be read, forcing a restart\n",
    "\n",
    "    logging.info(f\"Found {count} valid examples and {invalid_lines} invalid lines in '{file_path}'.\")\n",
    "    return count\n",
    "\n",
    "def generate_example_with_backoff(client, topic, max_retries=5):\n",
    "    \"\"\"\n",
    "    Generates an example with exponential backoff and jitter for rate limits.\n",
    "    \"\"\"\n",
    "    delay = BASE_DELAY\n",
    "    for attempt in range(max_retries + 1):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": GENERATOR_SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": f\"Generate a training example for: {topic}\"}\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "                max_tokens=2048,\n",
    "                timeout=30\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except RateLimitError as e:\n",
    "            if attempt < max_retries:\n",
    "                jitter = random.uniform(0, 1) # Add jitter\n",
    "                actual_delay = min(delay * (BACKOFF_FACTOR ** attempt) + jitter, MAX_DELAY)\n",
    "                logging.warning(f\"Rate limit hit for '{topic[:50]}...'. Retrying in {actual_delay:.2f}s (attempt {attempt + 1}/{max_retries}).\")\n",
    "                time.sleep(actual_delay)\n",
    "            else:\n",
    "                logging.error(f\"‚ùå Failed to generate example for '{topic[:50]}...' after {max_retries} retries due to rate limits: {e}\")\n",
    "                return None\n",
    "        except APIError as e:\n",
    "            logging.error(f\"‚ùå API error for '{topic[:50]}...': {e}\")\n",
    "            return None # Don't retry for other API errors\n",
    "        except Exception as e:\n",
    "            logging.error(f\"‚ùå Unexpected error for '{topic[:50]}...': {e}\")\n",
    "            return None # Don't retry for unexpected errors\n",
    "    return None # Should not be reached if max_retries > 0, but just in case\n",
    "\n",
    "def is_valid_response(text):\n",
    "    if not text:\n",
    "        return False\n",
    "    return (\n",
    "        \"<thinking>\" in text and\n",
    "        \"</thinking>\" in text and\n",
    "        \"<answer>\" in text and\n",
    "        \"</answer>\" in text and\n",
    "        \"```python\" in text\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "    # 1. Count existing examples\n",
    "    existing_count = count_existing_examples(OUTPUT_FILE)\n",
    "    logging.info(f\"üéØ Target total examples: {TARGET_TOTAL_EXAMPLES}\")\n",
    "    logging.info(f\"üìä Examples found in existing file: {existing_count}\")\n",
    "\n",
    "    # 2. Calculate how many more are needed\n",
    "    examples_needed = max(0, TARGET_TOTAL_EXAMPLES - existing_count)\n",
    "    logging.info(f\"‚ûï Examples to generate: {examples_needed}\")\n",
    "\n",
    "    if examples_needed == 0:\n",
    "        logging.info(\"üéâ The dataset already has the target number of examples or more. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # 3. Select topics for the missing examples\n",
    "    # This assumes topics can be reused if needed, or you can implement logic to track used topics\n",
    "    topics_to_use = CODE_TOPICS * ((examples_needed // len(CODE_TOPICS)) + 1)\n",
    "    topics_to_process = topics_to_use[:examples_needed] # Slice to get exactly the number needed\n",
    "\n",
    "    logging.info(f\"üöÄ Starting generation for {len(topics_to_process)} topics.\")\n",
    "\n",
    "    # 4. Open file in append mode and generate\n",
    "    batch = []\n",
    "    total_saved_this_run = 0\n",
    "\n",
    "    # Use the existing file in append mode\n",
    "    with open(OUTPUT_FILE, \"a\", encoding=\"utf-8\") as output_f:\n",
    "        for i, topic in enumerate(tqdm(topics_to_process, desc=\"Generating examples\")):\n",
    "            response = generate_example_with_backoff(client, topic)\n",
    "            if response and is_valid_response(response):\n",
    "                record = {\"prompt\": topic, \"chosen\": response}\n",
    "                batch.append(record)\n",
    "                # Write immediately to the open file handle\n",
    "                output_f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "                total_saved_this_run += 1\n",
    "                logging.info(f\"‚úÖ Valid example generated and appended for: {topic[:60]}...\")\n",
    "            else:\n",
    "                logging.warning(f\"‚ö†Ô∏è  Invalid or missing response for: {topic[:60]}...\")\n",
    "\n",
    "            # Flush system buffer periodically (not the batch, as we write immediately)\n",
    "            if (i + 1) % FLUSH_EVERY == 0:\n",
    "                output_f.flush() # Ensure data is written to disk\n",
    "                logging.info(f\"üíæ Flushed output buffer after {i+1} topics processed in this run.\")\n",
    "\n",
    "            # Use the base delay between requests, regardless of retries within generate_example_with_backoff\n",
    "            # This provides a baseline rate limit.\n",
    "            # The internal retry logic handles short-term bursts/surges.\n",
    "            time.sleep(BASE_DELAY) # Respect baseline rate limits\n",
    "\n",
    "    # 5. Final logging\n",
    "    final_total_count = existing_count + total_saved_this_run\n",
    "    logging.info(f\"\\nüéâ Done! Script run completed. Total examples in '{OUTPUT_FILE}' is now approximately {final_total_count}.\")\n",
    "    if final_total_count >= TARGET_TOTAL_EXAMPLES:\n",
    "        logging.info(f\"‚úÖ Target of {TARGET_TOTAL_EXAMPLES} examples reached or exceeded.\")\n",
    "    else:\n",
    "        logging.info(f\"‚ö†Ô∏è  Target was {TARGET_TOTAL_EXAMPLES}, but only {final_total_count} were found/created. Check logs for potential issues.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "6e710912acd929fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T06:57:37.754773Z",
     "start_time": "2025-11-09T06:57:37.749652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch, json, random\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from datasets import Dataset\n",
    "from peft import PeftModel\n",
    "from pathlib import Path\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# PATHS - UPDATE THESE\n",
    "BASE_MODEL = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\"\n",
    "STAGE_B_ADAPTER = \"Section-D/Universal-Code-Master/final_model\"\n",
    "STAGE_C_OUTPUT = \"Section-E/Universal-Code-Master\"\n",
    "YOUR_DATASET_PATH = \"Data/finetuning_dataset_v2.jsonl\"  # UPDATE THIS\n",
    "\n",
    "# TRAINING HYPERPARAMETERS (LOWER than Stage B)\n",
    "MAX_SEQ_LENGTH = 1408\n",
    "LEARNING_RATE = 5e-4  # 50% of Stage B (1e-5)\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 2\n",
    "GRAD_ACCUM = 4\n",
    "WARMUP_RATIO = 0.1\n",
    "\n",
    "# LORA CONFIG (same as Stage B)\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = 16\n",
    "LORA_DROPOUT = 0.0\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE:.2e} (50% of Stage B)\")\n",
    "print(f\"   Effective Batch Size: {BATCH_SIZE * GRAD_ACCUM}\")\n"
   ],
   "id": "4b4c3653a9718d81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded\n",
      "   Learning Rate: 5.00e-04 (50% of Stage B)\n",
      "   Effective Batch Size: 8\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T06:57:46.279354Z",
     "start_time": "2025-11-09T06:57:46.223814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# The path to your original, potentially flawed dataset file\n",
    "INPUT_DATASET_PATH = \"Data/code_finetune_dataset.jsonl\"\n",
    "\n",
    "# The path where the new, cleaned, and augmented dataset will be saved\n",
    "OUTPUT_DATASET_PATH = \"Data/finetuning_dataset_v2.jsonl\"\n",
    "\n",
    "# The unique stop word we will add to the end of every example\n",
    "STOP_WORD = \"[END]\"\n",
    "\n",
    "# --- SCRIPT LOGIC ---\n",
    "\n",
    "def clean_and_augment_response(response_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Applies a series of cleaning and augmentation rules to the response text.\n",
    "    \"\"\"\n",
    "    cleaned_text = response_text\n",
    "\n",
    "    # Rule 1: Remove duplicate </answer> tags.\n",
    "    # This regex finds \"</answer>\" potentially followed by whitespace and another \"</answer>\"\n",
    "    # and replaces it with a single \"</answer>\".\n",
    "    cleaned_text = re.sub(r'</answer>\\s*</answer>', '</answer>', cleaned_text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Rule 2: Ensure the structure is <think>...</think><answer>...</answer>\n",
    "    # This is a simple check. More complex validation could be added if needed.\n",
    "    if \"<think>\" not in cleaned_text or \"</think>\" not in cleaned_text:\n",
    "        # Handle cases where thinking tags might be missing (optional, based on your data)\n",
    "        pass # For now, we assume they are present\n",
    "\n",
    "    if \"<answer>\" not in cleaned_text or \"</answer>\" not in cleaned_text:\n",
    "        # This might indicate a more serious parsing error, but we'll proceed\n",
    "        pass\n",
    "\n",
    "    # Rule 3 (Augmentation): Append the stop word for consistent termination.\n",
    "    # We strip any trailing whitespace first, then add the stop word.\n",
    "    cleaned_text = cleaned_text.strip() + f\"\\n{STOP_WORD}\"\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process the dataset.\n",
    "    \"\"\"\n",
    "    print(f\"Reading from: {INPUT_DATASET_PATH}\")\n",
    "    print(f\"Writing cleaned and augmented data to: {OUTPUT_DATASET_PATH}\")\n",
    "\n",
    "    # Counters for statistics\n",
    "    total_lines = 0\n",
    "    processed_lines = 0\n",
    "\n",
    "    try:\n",
    "        with open(INPUT_DATASET_PATH, 'r', encoding='utf-8') as infile, \\\n",
    "             open(OUTPUT_DATASET_PATH, 'w', encoding='utf-8') as outfile:\n",
    "\n",
    "            # Count total lines for the progress bar\n",
    "            total_lines = sum(1 for line in infile)\n",
    "            infile.seek(0) # Reset file pointer after counting\n",
    "\n",
    "            for line in tqdm(infile, total=total_lines, desc=\"Processing dataset\"):\n",
    "                try:\n",
    "                    # Load the JSON object from the line\n",
    "                    data_record = json.loads(line)\n",
    "\n",
    "                    # Ensure the 'chosen' field exists\n",
    "                    if 'chosen' in data_record and isinstance(data_record['chosen'], str):\n",
    "                        original_response = data_record['chosen']\n",
    "\n",
    "                        # Apply our cleaning and augmentation function\n",
    "                        fixed_response = clean_and_augment_response(original_response)\n",
    "\n",
    "                        # Update the record with the fixed response\n",
    "                        data_record['chosen'] = fixed_response\n",
    "\n",
    "                        # Write the corrected JSON object to the new file\n",
    "                        outfile.write(json.dumps(data_record) + '\\n')\n",
    "                        processed_lines += 1\n",
    "\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"\\nWarning: Skipping a line due to JSON decoding error.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "\n",
    "        print(\"\\n--- Processing Complete ---\")\n",
    "        print(f\"Total lines read: {total_lines}\")\n",
    "        print(f\"Lines successfully processed and saved: {processed_lines}\")\n",
    "        print(f\"Your new dataset is ready at: {OUTPUT_DATASET_PATH}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file not found at '{INPUT_DATASET_PATH}'. Please check the path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during file operations: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "76771a910bdfe562",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: /home/aurduinonucleo/gemma-grpo-project/Data/code_finetune_dataset.jsonl\n",
      "Writing cleaned and augmented data to: /home/aurduinonucleo/gemma-grpo-project/Data/finetuning_dataset_v2.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 28559.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Complete ---\n",
      "Total lines read: 1000\n",
      "Lines successfully processed and saved: 1000\n",
      "Your new dataset is ready at: /home/aurduinonucleo/gemma-grpo-project/Data/finetuning_dataset_v2.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T06:58:05.629077Z",
     "start_time": "2025-11-09T06:58:05.625963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Detailed system prompt that forces correct thinking every time\n",
    "UNIVERSAL_CODING_SYSTEM_PROMPT = \"\"\"You are an elite software engineer who writes syntactically perfect, logically sound code across all programming languages.\n",
    "\n",
    "MANDATORY THINKING PROCESS - You MUST use <thinking> tags before <answer>:\n",
    "\n",
    "Inside <thinking>:\n",
    "1. RESTATE THE PROBLEM: Paraphrase the task in your own words to confirm understanding\n",
    "2. IDENTIFY CONSTRAINTS: List all input/output specs, data types, time/space complexity requirements\n",
    "3. ENUMERATE EDGE CASES: Empty inputs, null values, negative numbers, zero, boundary conditions, duplicates, special characters\n",
    "4. COMPARE APPROACHES: Analyze 2-3 different algorithms with their time/space complexity\n",
    "5. CHOOSE OPTIMAL APPROACH: Select the best algorithm and justify why (correctness, efficiency, readability)\n",
    "6. PLAN IMPLEMENTATION: Write pseudocode or step-by-step logic flow\n",
    "7. ANTICIPATE BUGS: Think through off-by-one errors, integer overflow, null pointer issues, index out of bounds\n",
    "\n",
    "Inside <answer>:\n",
    "- Write ONLY the complete, runnable code\n",
    "- Use proper syntax (correct indentation, matching braces, semicolons where needed)\n",
    "- Handle ALL edge cases explicitly in code\n",
    "- Use meaningful variable names\n",
    "- Add minimal inline comments only for complex logic\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- ALWAYS use <thinking> tags for your reasoning process\n",
    "- ALWAYS use <answer> tags for the final code\n",
    "- Code must be syntactically correct (no errors, proper formatting)\n",
    "- Code must be logically sound (handles edge cases, correct algorithm)\n",
    "- Code must be production-ready (no TODOs, no placeholder logic)\n",
    "\n",
    "LANGUAGE-SPECIFIC RULES:\n",
    "- Python: 4-space indentation, type hints, PEP 8 compliance\n",
    "- JavaScript: const/let (no var), proper semicolons, ES6+ syntax\n",
    "- C++: STL containers, RAII, proper memory management, const correctness\n",
    "- Java: Proper access modifiers, exception handling, naming conventions\n",
    "\n",
    "EDGE CASE CHECKLIST (verify in <thinking>):\n",
    "‚úì Empty collection (list/array/string)\n",
    "‚úì Single element\n",
    "‚úì Null/None/undefined values\n",
    "‚úì Negative numbers (if applicable)\n",
    "‚úì Zero\n",
    "‚úì Maximum/minimum integer values\n",
    "‚úì Duplicate elements\n",
    "‚úì Already sorted/reverse sorted (for sorting problems)\n",
    "‚úì Invalid input types\"\"\"\n",
    "\n",
    "print(\"‚úÖ Enhanced system prompt loaded\")\n",
    "print(f\"   Prompt length: {len(UNIVERSAL_CODING_SYSTEM_PROMPT)} characters\")\n"
   ],
   "id": "d7d5eaacb93c098c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced system prompt loaded\n",
      "   Prompt length: 2113 characters\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T06:58:28.159155Z",
     "start_time": "2025-11-09T06:58:08.903702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# CELL 4: Load Base Model + Stage B Adapter (NO MERGE - Preserve Precision)\n",
    "# ============================================================================\n",
    "import unsloth\n",
    "def setup_stage_c_model():\n",
    "    \"\"\"\n",
    "    Load base model and attach Stage B adapter WITHOUT merging.\n",
    "    This preserves precision and avoids 4-bit rounding errors.\n",
    "    \"\"\"\n",
    "    print(\"üß† Loading base model...\")\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=BASE_MODEL,\n",
    "        max_seq_length=MAX_SEQ_LENGTH,\n",
    "        dtype=\"bfloat16\" if is_bfloat16_supported() else \"float16\",\n",
    "        load_in_4bit=True,\n",
    "        device_map={\"\": 0},\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "    # Load Stage B adapter on top (don't merge - keep it as adapter)\n",
    "    print(f\"üîó Loading Stage B LoRA adapter from {STAGE_B_ADAPTER}\")\n",
    "    model = PeftModel.from_pretrained(model, STAGE_B_ADAPTER)\n",
    "\n",
    "    # CRITICAL: Mark Stage B adapter params as trainable for continued training\n",
    "    print(\"üîß Marking Stage B adapter parameters as trainable...\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"lora_\" in name:\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Memory optimization\n",
    "    model.enable_input_require_grads()\n",
    "    try:\n",
    "        model.gradient_checkpointing_enable()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Tokenizer safety\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "    print(\"‚úÖ Model + Stage B LoRA ready\")\n",
    "    print(f\"   Trainable params: {trainable_params:,} ({100 * trainable_params / total_params:.2f}%)\")\n",
    "    print(f\"   Total params: {total_params:,}\")\n",
    "    print(f\"   Training strategy: Continued training of Stage B adapters\")\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "# Load the model\n",
    "model, tokenizer = setup_stage_c_model()\n"
   ],
   "id": "8105c906674a0e2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Loading base model...\n",
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth 2025.10.12: Fast Llama patching. Transformers: 4.57.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3060. Num GPUs = 1. Max memory: 11.629 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "üîó Loading Stage B LoRA adapter from /home/aurduinonucleo/gemma-grpo-project/Section-D/Universal-Code-Master/final_model\n",
      "üîß Marking Stage B adapter parameters as trainable...\n",
      "‚úÖ Model + Stage B LoRA ready\n",
      "   Trainable params: 24,313,856 (1.33%)\n",
      "   Total params: 1,827,777,536\n",
      "   Training strategy: Continued training of Stage B adapters\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T06:58:43.328462Z",
     "start_time": "2025-11-09T06:58:43.249033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load your dataset with format: {\"prompt\": \"...\", \"chosen\": \"<thinking>...</thinking><answer>...</answer>\"}\n",
    "print(\"üìÇ Loading dataset...\")\n",
    "\n",
    "dataset_items = []\n",
    "with open(YOUR_DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line.strip())\n",
    "        dataset_items.append(item)\n",
    "\n",
    "# Convert to chat format matching Stage B\n",
    "def format_for_training(example):\n",
    "    \"\"\"Convert your format to chat messages\"\"\"\n",
    "    prompt = example['prompt']\n",
    "    chosen = example['chosen']\n",
    "\n",
    "    # Create chat messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": UNIVERSAL_CODING_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": chosen}\n",
    "    ]\n",
    "\n",
    "    # Apply chat template\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "\n",
    "    return {\"text\": text}\n",
    "\n",
    "# Format all examples\n",
    "formatted_data = [format_for_training(item) for item in dataset_items]\n",
    "dataset = Dataset.from_list(formatted_data)\n",
    "\n",
    "print(f\"‚úÖ Dataset prepared: {len(dataset)} examples\")\n",
    "print(f\"   Format: prompt + <thinking> + <answer> structure\")\n"
   ],
   "id": "2db02154f826c813",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading dataset...\n",
      "‚úÖ Dataset prepared: 1000 examples\n",
      "   Format: prompt + <thinking> + <answer> structure\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T06:58:45.955514Z",
     "start_time": "2025-11-09T06:58:45.921429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# CELL 6: Setup Training Arguments (WITH CHECKPOINT RESUME)\n",
    "# ============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def find_latest_checkpoint():\n",
    "    \"\"\"Find the most recent checkpoint in output directory\"\"\"\n",
    "    out = Path(STAGE_C_OUTPUT)\n",
    "    if not out.exists():\n",
    "        return None\n",
    "\n",
    "    checkpoints = []\n",
    "    for p in out.iterdir():\n",
    "        if p.is_dir() and p.name.startswith(\"checkpoint-\"):\n",
    "            try:\n",
    "                step = int(p.name.split(\"-\")[1])\n",
    "                checkpoints.append((step, str(p)))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    if not checkpoints:\n",
    "        return None\n",
    "\n",
    "    checkpoints.sort(key=lambda x: x[0])\n",
    "    latest = checkpoints[-1]\n",
    "    print(f\"‚úÖ Found checkpoint at step {latest[0]}: {latest[1]}\")\n",
    "    return latest[1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=STAGE_C_OUTPUT,\n",
    "    overwrite_output_dir=False,  # CRITICAL: Don't overwrite checkpoints\n",
    "\n",
    "    # Training schedule\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM,\n",
    "\n",
    "    # Learning rate (LOWER than Stage B)\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "\n",
    "    # Optimization\n",
    "    optim=\"adamw_8bit\",\n",
    "    fp16=not is_bfloat16_supported(),\n",
    "    bf16=is_bfloat16_supported(),\n",
    "    tf32=True if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else False,\n",
    "\n",
    "    # Saving (saves every 50 steps, keeps last 3 checkpoints)\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    save_total_limit=3,\n",
    "\n",
    "    # Logging\n",
    "    logging_dir=f\"{STAGE_C_OUTPUT}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "\n",
    "    # Memory optimization\n",
    "    dataloader_pin_memory=False,\n",
    "    dataloader_num_workers=0,\n",
    "    remove_unused_columns=False,\n",
    "\n",
    "    # Stability\n",
    "    max_grad_norm=1.0,\n",
    "    seed=42,\n",
    "    data_seed=42,\n",
    "\n",
    "    report_to=[],\n",
    ")\n",
    "\n",
    "# Check for existing checkpoint\n",
    "resume_checkpoint = find_latest_checkpoint()\n",
    "\n",
    "print(\"‚úÖ Training arguments configured\")\n",
    "print(f\"   Total steps: {len(dataset) // (BATCH_SIZE * GRAD_ACCUM)}\")\n",
    "if resume_checkpoint:\n",
    "    print(f\"   üîÑ Will RESUME from: {resume_checkpoint}\")\n",
    "else:\n",
    "    print(\"   üÜï Starting fresh training\")\n"
   ],
   "id": "bdf564f54b2ab0e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training arguments configured\n",
      "   Total steps: 125\n",
      "   üÜï Starting fresh training\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:18:27.315174Z",
     "start_time": "2025-11-09T06:58:47.525846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# CELL 7: Create Trainer and Start Training (WITH RESUME)\n",
    "# ============================================================================\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    args=training_args,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    dataset_text_field=\"text\",\n",
    "    packing=False,\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting Stage C training...\")\n",
    "print(f\"   Strategy: Continued training on merged Stage A+B model\")\n",
    "print(f\"   Learning rate: {LEARNING_RATE:.2e} (50% of Stage B)\")\n",
    "print(f\"   Dataset: {len(dataset)} examples\")\n",
    "\n",
    "# Resume from checkpoint if exists\n",
    "if resume_checkpoint:\n",
    "    print(f\"\\nüîÑ RESUMING from checkpoint: {resume_checkpoint}\")\n",
    "    trainer.train(resume_from_checkpoint=resume_checkpoint)\n",
    "else:\n",
    "    print(\"\\nüÜï Starting fresh training\")\n",
    "    trainer.train()\n",
    "\n",
    "print(\"\\n‚úÖ Stage C training complete!\")\n"
   ],
   "id": "6af58789e0845fde",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=20):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e585e4978c5145e0b0eb9b5c87b3bd2d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Stage C training...\n",
      "   Strategy: Continued training on merged Stage A+B model\n",
      "   Learning rate: 5.00e-04 (50% of Stage B)\n",
      "   Dataset: 1000 examples\n",
      "\n",
      "üÜï Starting fresh training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,000 | Num Epochs = 1 | Total steps = 125\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 24,313,856 of 3,237,063,680 (0.75% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 19:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.308200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.306500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.314500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.262700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.290500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.268400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.302800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.298700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.278000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.278300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.292900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "47fe26071530e664619e80863733d14b"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Stage C training complete!\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T07:18:33.858887Z",
     "start_time": "2025-11-09T07:18:32.464806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_dir = f\"{STAGE_C_OUTPUT}/final_model\"\n",
    "print(f\"üíæ Saving final Stage C adapter to {final_dir}...\")\n",
    "\n",
    "model.save_pretrained(final_dir)\n",
    "tokenizer.save_pretrained(final_dir)\n",
    "\n",
    "print(\"\\n‚úÖ Stage C model saved successfully!\")\n",
    "print(\"\\nüìä Training Pipeline Complete:\")\n",
    "print(\"   Stage A: GRPO code optimization\")\n",
    "print(\"   Stage B: Reasoning + thinking\")\n",
    "print(\"   Stage C: Universal multi-language coding ‚úì\")\n"
   ],
   "id": "ec627f3797c8945",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving final Stage C adapter to /home/aurduinonucleo/gemma-grpo-project/Section-E/Universal-Code-Master/final_model...\n",
      "\n",
      "‚úÖ Stage C model saved successfully!\n",
      "\n",
      "üìä Training Pipeline Complete:\n",
      "   Stage A: GRPO code optimization\n",
      "   Stage B: Reasoning + thinking\n",
      "   Stage C: Universal multi-language coding ‚úì\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T08:02:58.218059Z",
     "start_time": "2025-11-14T08:00:50.087846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# run_chat_healed.py (Final Version with Streaming + Self-Healing)\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import re\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList, TextStreamer\n",
    "\n",
    "# ==============================================================================\n",
    "#  STEP 1: CONFIGURATION\n",
    "# ==============================================================================\n",
    "# üö® UPDATE THIS PATH to your final LoRA adapter üö®\n",
    "LORA_ADAPTER_PATH = \"Section-D/Universal-Code-Master/final_model\"\n",
    "\n",
    "BASE_MODEL_PATH = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\"\n",
    "MAX_SEQ_LENGTH = 2048\n",
    "SPECIAL_STOP_TOKEN = \"[END]\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an elite software engineer who writes syntactically perfect, logically sound code across all programming languages.\n",
    "\n",
    "MANDATORY THINKING PROCESS - You MUST use <thinking> tags before <answer>:\n",
    "\n",
    "Inside <thinking>:\n",
    "1. RESTATE THE PROBLEM: Paraphrase the task in your own words to confirm understanding\n",
    "2. IDENTIFY CONSTRAINTS: List all input/output specs, data types, time/space complexity requirements\n",
    "3. ENUMERATE EDGE CASES: Empty inputs, null values, negative numbers, zero, boundary conditions, duplicates, special characters\n",
    "4. COMPARE APPROACHES: Analyze 2-3 different algorithms with their time/space complexity\n",
    "5. CHOOSE OPTIMAL APPROACH: Select the best algorithm and justify why (correctness, efficiency, readability)\n",
    "6. PLAN IMPLEMENTATION: Write pseudocode or step-by-step logic flow\n",
    "7. ANTICIPATE BUGS: Think through off-by-one errors, integer overflow, null pointer issues, index out of bounds\n",
    "\n",
    "Inside <answer>:\n",
    "- Write ONLY the complete, runnable code\n",
    "- Use proper syntax (correct indentation, matching braces, semicolons where needed)\n",
    "- Handle ALL edge cases explicitly in code\n",
    "- Use meaningful variable names\n",
    "- Add minimal inline comments only for complex logic\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "- ALWAYS use <thinking> tags for your reasoning process\n",
    "- ALWAYS use <answer> tags for the final code\n",
    "- Code must be syntactically correct (no errors, proper formatting)\n",
    "- Code must be logically sound (handles edge cases, correct algorithm)\n",
    "- Code must be production-ready (no TODOs, no placeholder logic)\n",
    "\n",
    "LANGUAGE-SPECIFIC RULES:\n",
    "- Python: 4-space indentation, type hints, PEP 8 compliance\n",
    "- JavaScript: const/let (no var), proper semicolons, ES6+ syntax\n",
    "- C++: STL containers, RAII, proper memory management, const correctness\n",
    "- Java: Proper access modifiers, exception handling, naming conventions\n",
    "\n",
    "EDGE CASE CHECKLIST (verify in <thinking>):\n",
    "‚úì Empty collection (list/array/string)\n",
    "‚úì Single element\n",
    "‚úì Null/None/undefined values\n",
    "‚úì Negative numbers (if applicable)\n",
    "‚úì Zero\n",
    "‚úì Maximum/minimum integer values\n",
    "‚úì Duplicate elements\n",
    "‚úì Already sorted/reverse sorted (for sorting problems)\n",
    "‚úì Invalid input types\"\"\"\n",
    "\n",
    "# ==============================================================================\n",
    "#  STEP 2: UTILITIES AND HELPER CLASSES\n",
    "# ==============================================================================\n",
    "class StopOnToken(StoppingCriteria):\n",
    "    def __init__(self, stop_token_id):\n",
    "        self.stop_token_id = stop_token_id\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        return input_ids[0, -1] == self.stop_token_id\n",
    "\n",
    "def load_model(base_model_path, lora_adapter_path):\n",
    "    print(\"Loading base model...\")\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=base_model_path, max_seq_length=MAX_SEQ_LENGTH, dtype=None, load_in_4bit=True\n",
    "    )\n",
    "    tokenizer.add_special_tokens({\"additional_special_tokens\": [SPECIAL_STOP_TOKEN]})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    print(f\"Applying LoRA adapter from: {lora_adapter_path}\")\n",
    "    model.load_adapter(lora_adapter_path)\n",
    "    print(\"Optimizing model for inference...\")\n",
    "    FastLanguageModel.for_inference(model)\n",
    "    return model, tokenizer\n",
    "\n",
    "def chat_with_model(model, tokenizer, user_prompt):\n",
    "    \"\"\"Formats the prompt, generates a response with streaming, and returns the full text.\"\"\"\n",
    "    stop_token_id = tokenizer.convert_tokens_to_ids(SPECIAL_STOP_TOKEN)\n",
    "    stopping_criteria = StoppingCriteriaList([StopOnToken(stop_token_id)])\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "    formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=2048,\n",
    "        temperature=0.2,\n",
    "        do_sample=True,\n",
    "        stopping_criteria=stopping_criteria,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"\\n\\n(Full response generated in {end_time - start_time:.2f} seconds)\")\n",
    "    full_response = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "    return full_response.replace(SPECIAL_STOP_TOKEN, \"\").strip()\n",
    "\n",
    "def heal_and_reprint_if_needed(raw_response: str):\n",
    "    \"\"\"\n",
    "    Checks the response for closing tags. If any are missing, it prints a healed version.\n",
    "    \"\"\"\n",
    "    was_healed = False\n",
    "    healed_response = raw_response\n",
    "\n",
    "    # Heal missing </thinking> tag\n",
    "    if \"<thinking>\" in healed_response and \"</thinking>\" not in healed_response:\n",
    "        answer_pos = healed_response.find(\"<answer>\")\n",
    "        if answer_pos != -1:\n",
    "            healed_response = healed_response[:answer_pos] + \"</thinking>\\n\\n\" + healed_response[answer_pos:]\n",
    "            was_healed = True\n",
    "\n",
    "    # Heal missing </answer> tag\n",
    "    if \"<answer>\" in healed_response and \"</answer>\" not in healed_response:\n",
    "        healed_response += \"\\n</answer>\"\n",
    "        was_healed = True\n",
    "\n",
    "    # ONLY if we made a change, print the corrected block\n",
    "    if was_healed:\n",
    "        print(\"\\n\" + \"=\"*40 + \" HEALED RESPONSE \" + \"=\"*40)\n",
    "        print(\"[SYSTEM] Original output was malformed. Displaying corrected version:\")\n",
    "        print(\"-\" * 96)\n",
    "        print(healed_response)\n",
    "        print(\"=\"*96)\n",
    "\n",
    "# ==============================================================================\n",
    "#  STEP 3: MAIN EXECUTION LOOP\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = load_model(BASE_MODEL_PATH, LORA_ADAPTER_PATH)\n",
    "\n",
    "    print(\"\\n\\n‚úÖ Model is ready. Enter your code prompt below.\")\n",
    "    print(\"   Type 'exit' or 'quit' to close the script.\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            user_input = input(\"\\n>> Prompt: \")\n",
    "            if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "                break\n",
    "\n",
    "            print(\"\\nü§ñ Model Response (Streaming):\\n\" + \"-\"*30)\n",
    "            raw_response = chat_with_model(model, tokenizer, user_input)\n",
    "\n",
    "            # After streaming, silently check and heal the response if necessary\n",
    "            heal_and_reprint_if_needed(raw_response)\n",
    "\n",
    "    except KeyboardInterrupt:1Q\n",
    "        print(\"\\n\\nExiting...\")\n",
    "\n",
    "    print(\"\\nInference script finished.\")"
   ],
   "id": "d4fbc1a36f9490be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model...\n",
      "==((====))==  Unsloth 2025.10.12: Fast Llama patching. Transformers: 4.57.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3060. Num GPUs = 1. Max memory: 11.629 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Applying LoRA adapter from: /home/aurduinonucleo/gemma-grpo-project/Section-D/Universal-Code-Master/final_model\n",
      "Optimizing model for inference...\n",
      "\n",
      "\n",
      "‚úÖ Model is ready. Enter your code prompt below.\n",
      "   Type 'exit' or 'quit' to close the script.\n",
      "--------------------------------------------------\n",
      "\n",
      "ü§ñ Model Response (Streaming):\n",
      "------------------------------\n",
      "<thinking>\n",
      "- The task is to write a Python function that prints \"Hello\".\n",
      "- Two possible approaches are: \n",
      "  1. Using a simple print statement.\n",
      "  2. Using a function that takes no arguments and prints \"Hello\".\n",
      "- For the first approach, the time complexity is O(1) because it involves a constant number of operations, and the space complexity is also O(1) as it doesn't use any additional space that scales with input size.\n",
      "- For the second approach, the time complexity is also O(1) for the same reason, and the space complexity is O(1) as well.\n",
      "- The first approach is more straightforward and efficient for this simple task.\n",
      "- Key edge cases include: an empty input (which is not applicable here), a None input, and printing \"Hello\" in a context where it might be expected to handle different inputs (e.g., a function that should handle different messages).\n",
      "- Justification for choosing the first approach: it is the most direct and efficient way to print \"Hello\" without any additional complexity.\n",
      "</thinking>\n",
      "\n",
      "<answer>\n",
      "```python\n",
      "def print_hello() -> None:\n",
      "    \"\"\"\n",
      "    Prints \"Hello\" to the console.\n",
      "\n",
      "    This function is designed to be simple and efficient, printing \"Hello\" directly.\n",
      "    \"\"\"\n",
      "    print(\"Hello\")\n",
      "\n",
      "# Example usage:\n",
      "print_hello()\n",
      "```\n",
      "</answer>\n",
      "[END]\n",
      "\n",
      "\n",
      "(Full response generated in 10.55 seconds)\n",
      "\n",
      "\n",
      "Exiting...\n",
      "\n",
      "Inference script finished.\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
